{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import min\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = spark.read.csv('en.openfoodfacts.org.products.csv',header=True,sep='\\t') \n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code',\n",
       " 'url',\n",
       " 'creator',\n",
       " 'created_t',\n",
       " 'created_datetime',\n",
       " 'last_modified_t',\n",
       " 'last_modified_datetime',\n",
       " 'product_name',\n",
       " 'generic_name',\n",
       " 'quantity',\n",
       " 'packaging',\n",
       " 'packaging_tags',\n",
       " 'brands',\n",
       " 'brands_tags',\n",
       " 'categories',\n",
       " 'categories_tags',\n",
       " 'categories_en',\n",
       " 'origins',\n",
       " 'origins_tags',\n",
       " 'manufacturing_places',\n",
       " 'manufacturing_places_tags',\n",
       " 'labels',\n",
       " 'labels_tags',\n",
       " 'labels_en',\n",
       " 'emb_codes',\n",
       " 'emb_codes_tags',\n",
       " 'first_packaging_code_geo',\n",
       " 'cities',\n",
       " 'cities_tags',\n",
       " 'purchase_places',\n",
       " 'stores',\n",
       " 'countries',\n",
       " 'countries_tags',\n",
       " 'countries_en',\n",
       " 'ingredients_text',\n",
       " 'allergens',\n",
       " 'allergens_en',\n",
       " 'traces',\n",
       " 'traces_tags',\n",
       " 'traces_en',\n",
       " 'serving_size',\n",
       " 'serving_quantity',\n",
       " 'no_nutriments',\n",
       " 'additives_n',\n",
       " 'additives',\n",
       " 'additives_tags',\n",
       " 'additives_en',\n",
       " 'ingredients_from_palm_oil_n',\n",
       " 'ingredients_from_palm_oil',\n",
       " 'ingredients_from_palm_oil_tags',\n",
       " 'ingredients_that_may_be_from_palm_oil_n',\n",
       " 'ingredients_that_may_be_from_palm_oil',\n",
       " 'ingredients_that_may_be_from_palm_oil_tags',\n",
       " 'nutrition_grade_uk',\n",
       " 'nutrition_grade_fr',\n",
       " 'pnns_groups_1',\n",
       " 'pnns_groups_2',\n",
       " 'states',\n",
       " 'states_tags',\n",
       " 'states_en',\n",
       " 'main_category',\n",
       " 'main_category_en',\n",
       " 'image_url',\n",
       " 'image_small_url',\n",
       " 'image_ingredients_url',\n",
       " 'image_ingredients_small_url',\n",
       " 'image_nutrition_url',\n",
       " 'image_nutrition_small_url',\n",
       " 'energy_100g',\n",
       " 'energy-from-fat_100g',\n",
       " 'fat_100g',\n",
       " 'saturated-fat_100g',\n",
       " '-butyric-acid_100g',\n",
       " '-caproic-acid_100g',\n",
       " '-caprylic-acid_100g',\n",
       " '-capric-acid_100g',\n",
       " '-lauric-acid_100g',\n",
       " '-myristic-acid_100g',\n",
       " '-palmitic-acid_100g',\n",
       " '-stearic-acid_100g',\n",
       " '-arachidic-acid_100g',\n",
       " '-behenic-acid_100g',\n",
       " '-lignoceric-acid_100g',\n",
       " '-cerotic-acid_100g',\n",
       " '-montanic-acid_100g',\n",
       " '-melissic-acid_100g',\n",
       " 'monounsaturated-fat_100g',\n",
       " 'polyunsaturated-fat_100g',\n",
       " 'omega-3-fat_100g',\n",
       " '-alpha-linolenic-acid_100g',\n",
       " '-eicosapentaenoic-acid_100g',\n",
       " '-docosahexaenoic-acid_100g',\n",
       " 'omega-6-fat_100g',\n",
       " '-linoleic-acid_100g',\n",
       " '-arachidonic-acid_100g',\n",
       " '-gamma-linolenic-acid_100g',\n",
       " '-dihomo-gamma-linolenic-acid_100g',\n",
       " 'omega-9-fat_100g',\n",
       " '-oleic-acid_100g',\n",
       " '-elaidic-acid_100g',\n",
       " '-gondoic-acid_100g',\n",
       " '-mead-acid_100g',\n",
       " '-erucic-acid_100g',\n",
       " '-nervonic-acid_100g',\n",
       " 'trans-fat_100g',\n",
       " 'cholesterol_100g',\n",
       " 'carbohydrates_100g',\n",
       " 'sugars_100g',\n",
       " '-sucrose_100g',\n",
       " '-glucose_100g',\n",
       " '-fructose_100g',\n",
       " '-lactose_100g',\n",
       " '-maltose_100g',\n",
       " '-maltodextrins_100g',\n",
       " 'starch_100g',\n",
       " 'polyols_100g',\n",
       " 'fiber_100g',\n",
       " 'proteins_100g',\n",
       " 'casein_100g',\n",
       " 'serum-proteins_100g',\n",
       " 'nucleotides_100g',\n",
       " 'salt_100g',\n",
       " 'sodium_100g',\n",
       " 'alcohol_100g',\n",
       " 'vitamin-a_100g',\n",
       " 'beta-carotene_100g',\n",
       " 'vitamin-d_100g',\n",
       " 'vitamin-e_100g',\n",
       " 'vitamin-k_100g',\n",
       " 'vitamin-c_100g',\n",
       " 'vitamin-b1_100g',\n",
       " 'vitamin-b2_100g',\n",
       " 'vitamin-pp_100g',\n",
       " 'vitamin-b6_100g',\n",
       " 'vitamin-b9_100g',\n",
       " 'folates_100g',\n",
       " 'vitamin-b12_100g',\n",
       " 'biotin_100g',\n",
       " 'pantothenic-acid_100g',\n",
       " 'silica_100g',\n",
       " 'bicarbonate_100g',\n",
       " 'potassium_100g',\n",
       " 'chloride_100g',\n",
       " 'calcium_100g',\n",
       " 'phosphorus_100g',\n",
       " 'iron_100g',\n",
       " 'magnesium_100g',\n",
       " 'zinc_100g',\n",
       " 'copper_100g',\n",
       " 'manganese_100g',\n",
       " 'fluoride_100g',\n",
       " 'selenium_100g',\n",
       " 'chromium_100g',\n",
       " 'molybdenum_100g',\n",
       " 'iodine_100g',\n",
       " 'caffeine_100g',\n",
       " 'taurine_100g',\n",
       " 'ph_100g',\n",
       " 'fruits-vegetables-nuts_100g',\n",
       " 'fruits-vegetables-nuts-estimate_100g',\n",
       " 'collagen-meat-protein-ratio_100g',\n",
       " 'cocoa_100g',\n",
       " 'chlorophyl_100g',\n",
       " 'carbon-footprint_100g',\n",
       " 'nutrition-score-fr_100g',\n",
       " 'nutrition-score-uk_100g',\n",
       " 'glycemic-index_100g',\n",
       " 'water-hardness_100g',\n",
       " 'choline_100g',\n",
       " 'phylloquinone_100g',\n",
       " 'beta-glucan_100g',\n",
       " 'inositol_100g',\n",
       " 'carnitine_100g']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|       packaging| count|\n",
      "+----------------+------+\n",
      "|            null|553446|\n",
      "|sachet,plastique|  4425|\n",
      "|Sachet,Plastique|  3160|\n",
      "| Bouteille,Verre|  2696|\n",
      "|       Plastique|  2491|\n",
      "+----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analyse and cleaning the data, choosing what to do according what data we have: FIRST WEEK\n",
    "\n",
    "data_rdd.groupBy(\"packaging\").count().orderBy('count',ascending=False).show(5)\n",
    "from pyspark.sql import functions as F\n",
    "total = packaging.groupBy().agg(F.sum(\"count\")).collect()\n",
    "#the first analys on packaging we meant to be , it can not take place because the amount of null is way higher respect to the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|         brands| count|\n",
      "+---------------+------+\n",
      "|           null|229610|\n",
      "|      Carrefour|  5410|\n",
      "|         Auchan|  5324|\n",
      "|              U|  4405|\n",
      "|         Casino|  3129|\n",
      "|   Leader Price|  2846|\n",
      "|           Cora|  2234|\n",
      "|         Meijer|  1997|\n",
      "|         Kroger|  1673|\n",
      "|         Picard|  1521|\n",
      "|          Ahold|  1370|\n",
      "|          Netto|  1349|\n",
      "|        Spartan|  1341|\n",
      "|         Nestlé|  1322|\n",
      "|    Great Value|  1304|\n",
      "|       Roundy's|  1299|\n",
      "|       Monoprix|  1245|\n",
      "|       Delhaize|  1190|\n",
      "|           Coop|  1132|\n",
      "|   Belle France|  1130|\n",
      "|           Weis|  1055|\n",
      "|  La Vie Claire|   997|\n",
      "|Marks & Spencer|   995|\n",
      "|       Franprix|   971|\n",
      "|  Fleury Michon|   962|\n",
      "+---------------+------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data_rdd.groupBy('brands').count().orderBy('count',ascending=False).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "condition should be string or Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-439e6cab673b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_rdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"brands\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNotNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Carrefour'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: condition should be string or Column"
     ]
    }
   ],
   "source": [
    "data_rdd\n",
    "data_rdd.groupBy([\"brands\",\"product_name\"]).count().orderBy('count',ascending=False).where(data_rdd.brands.isNotNull()).filter(lambda x:x=='Carrefour').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|     categories_tags| count|\n",
      "+--------------------+------+\n",
      "|                null|514309|\n",
      "|en:beverages,en:n...|  5124|\n",
      "|             en:fats|  1799|\n",
      "|en:beverages,en:s...|  1674|\n",
      "|en:sugary-snacks,...|  1368|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"categories_tags\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`Carrefour`' given input columns: [brands, count]; line 1 pos 0;\\n'Filter 'Carrefour\\n+- AnalysisBarrier\\n      +- Sort [count#1291L DESC NULLS LAST], true\\n         +- Aggregate [brands#22], [brands#22, count(1) AS count#1291L]\\n            +- Relation[code#10,url#11,creator#12,created_t#13,created_datetime#14,last_modified_t#15,last_modified_datetime#16,product_name#17,generic_name#18,quantity#19,packaging#20,packaging_tags#21,brands#22,brands_tags#23,categories#24,categories_tags#25,categories_en#26,origins#27,origins_tags#28,manufacturing_places#29,manufacturing_places_tags#30,labels#31,labels_tags#32,labels_en#33,... 149 more fields] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/pkgs/pyspark-2.3.1-py36_1001/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o315.filter.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`Carrefour`' given input columns: [brands, count]; line 1 pos 0;\n'Filter 'Carrefour\n+- AnalysisBarrier\n      +- Sort [count#1291L DESC NULLS LAST], true\n         +- Aggregate [brands#22], [brands#22, count(1) AS count#1291L]\n            +- Relation[code#10,url#11,creator#12,created_t#13,created_datetime#14,last_modified_t#15,last_modified_datetime#16,product_name#17,generic_name#18,quantity#19,packaging#20,packaging_tags#21,brands#22,brands_tags#23,categories#24,categories_tags#25,categories_en#26,origins#27,origins_tags#28,manufacturing_places#29,manufacturing_places_tags#30,labels#31,labels_tags#32,labels_en#33,... 149 more fields] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:88)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:80)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:92)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:172)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:178)\n\tat org.apache.spark.sql.Dataset$.apply(Dataset.scala:65)\n\tat org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3301)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1458)\n\tat org.apache.spark.sql.Dataset.filter(Dataset.scala:1472)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2e3d2ac30e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"brands\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Carrefour'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \"\"\"\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/pkgs/pyspark-2.3.1-py36_1001/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`Carrefour`' given input columns: [brands, count]; line 1 pos 0;\\n'Filter 'Carrefour\\n+- AnalysisBarrier\\n      +- Sort [count#1291L DESC NULLS LAST], true\\n         +- Aggregate [brands#22], [brands#22, count(1) AS count#1291L]\\n            +- Relation[code#10,url#11,creator#12,created_t#13,created_datetime#14,last_modified_t#15,last_modified_datetime#16,product_name#17,generic_name#18,quantity#19,packaging#20,packaging_tags#21,brands#22,brands_tags#23,categories#24,categories_tags#25,categories_en#26,origins#27,origins_tags#28,manufacturing_places#29,manufacturing_places_tags#30,labels#31,labels_tags#32,labels_en#33,... 149 more fields] csv\\n\""
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"brands\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|         origins| count|\n",
      "+----------------+------+\n",
      "|            null|650941|\n",
      "|          France| 11016|\n",
      "|Union Européenne|  1524|\n",
      "|          Italie|   936|\n",
      "|         Espagne|   865|\n",
      "+----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"origins\").count().orderBy('count',ascending=False).show(5)#france,France,FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|manufacturing_places| count|\n",
      "+--------------------+------+\n",
      "|                null|626138|\n",
      "|              France| 18422|\n",
      "|              Italie|  2370|\n",
      "|            Belgique|  1408|\n",
      "|           Allemagne|  1241|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"manufacturing_places\").count().orderBy('count',ascending=False).show(5)#france,France,FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|              labels| count|\n",
      "+--------------------+------+\n",
      "|                null|591148|\n",
      "|          en:organic| 13371|\n",
      "|          Point Vert|  5234|\n",
      "|                 Bio|  2593|\n",
      "|Bio,Bio européen,...|  1906|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"labels\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|  purchase_places| count|\n",
      "+-----------------+------+\n",
      "|             null|592657|\n",
      "|           France| 30886|\n",
      "|      Lyon,France|  3464|\n",
      "|Courrières,France|  2474|\n",
      "|    France,Nantes|  2430|\n",
      "+-----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"purchase_places\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|    stores| count|\n",
      "+----------+------+\n",
      "|      null|602239|\n",
      "|Magasins U| 11800|\n",
      "| Carrefour|  7098|\n",
      "|   Leclerc|  4288|\n",
      "|    Auchan|  3981|\n",
      "+----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"stores\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "| countries_en| count|\n",
      "+-------------+------+\n",
      "|       France|418539|\n",
      "|United States|173557|\n",
      "|  Switzerland| 13488|\n",
      "|      Germany| 11807|\n",
      "|        Spain|  6169|\n",
      "+-------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"countries_en\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|saturated-fat_100g| count|\n",
      "+------------------+------+\n",
      "|              null|133117|\n",
      "|                 0|124448|\n",
      "|               0.1| 25871|\n",
      "|               0.5| 10980|\n",
      "|               0.2| 10751|\n",
      "+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_rdd.groupBy(\"saturated-fat_100g\").count().orderBy('count',ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "condition should be string or Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-b3f71a1d6854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#for all the column count the numbe rof the null values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ada/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: condition should be string or Column"
     ]
    }
   ],
   "source": [
    "#for all the column count the numbe rof the null values:\n",
    "data_rdd.filter(lambda x: sum(isnull(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
